{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc56a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Knowledge Cohort(knowledge extract):Knowledge Extraction\n",
    "import os, sys, logging, autogen\n",
    "from configs import GPT_MINI_CONFIG, MAX_ROUND \n",
    "try:\n",
    "    from CeProAgents import KnowledgeGroup\n",
    "except ImportError:\n",
    "    sys.path.append(os.path.abspath(\"..\")) \n",
    "    from CeProAgents import KnowledgeGroup\n",
    "\n",
    "INPUT_DIR = \"./CeProBench/knowledge/knowledge_raw\" \n",
    "WORK_DIR = \"./workdir/knowledge_extract\"            \n",
    "TARGET_ID = 1                                       \n",
    "LLM_CONFIG = GPT_MINI_CONFIG                        \n",
    "\n",
    "def get_file_path(base_dir, file_id):\n",
    "    if not os.path.exists(base_dir): return None\n",
    "    for f in os.listdir(base_dir):\n",
    "        if f.startswith(f\"{file_id}_\"): return os.path.join(base_dir, f)\n",
    "    for ext in ['.txt', '.md', '.json', '.pdf']:\n",
    "        path = os.path.join(base_dir, f\"{file_id}{ext}\")\n",
    "        if os.path.exists(path): return path\n",
    "    return None\n",
    "\n",
    "input_path = get_file_path(INPUT_DIR, TARGET_ID)\n",
    "\n",
    "if input_path:\n",
    "    file_name = os.path.basename(input_path)\n",
    "    output_dir = os.path.abspath(os.path.join(WORK_DIR, \"demo_run\", os.path.splitext(file_name)[0]))\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"üöÄ [Start] Ingesting: {file_name}\")\n",
    "    print(f\"üìÇ [Target] Saving to: {output_dir}\")\n",
    "\n",
    "    manager = KnowledgeGroup(LLM_CONFIG, MAX_ROUND).get_manager()\n",
    "    user = autogen.UserProxyAgent(name=\"User\", human_input_mode=\"NEVER\", code_execution_config=False, max_consecutive_auto_reply=1)\n",
    "\n",
    "    task_msg = f\"\"\"Command: INGEST\n",
    "        Source File: \"{os.path.abspath(input_path)}\"\n",
    "        Target Directory: \"{output_dir}\"\n",
    "\n",
    "        Instructions:\n",
    "        1. Read the Source File.\n",
    "        2. Build the knowledge base.\n",
    "        3. Save index/data files to the Target Directory.\"\"\"\n",
    "\n",
    "    user.initiate_chat(manager, message=task_msg)\n",
    "    print(f\"‚úÖ [Done] Task finished for ID {TARGET_ID}\")\n",
    "else:\n",
    "    print(f\"‚ùå [Error] File with ID {TARGET_ID} not found in {INPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb2b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Knowledge Cohort(knowledge augment): Multi-Agent QA\n",
    "import os, json, logging, autogen\n",
    "from configs import GPT_CONFIG, MAX_ROUND\n",
    "try:\n",
    "    from CeProAgents import KnowledgeGroup\n",
    "except ImportError:\n",
    "    import sys\n",
    "    sys.path.append(os.path.abspath(\"..\"))\n",
    "    from CeProAgents import KnowledgeGroup\n",
    "\n",
    "WORK_DIR = \"./workdir/knowledge_augment\"\n",
    "LLM_CONFIG = GPT_CONFIG  \n",
    "\n",
    "DEMO_TASK = {\n",
    "    \"id\": 1,\n",
    "    \"class\": \"General\",\n",
    "    \"question\": \"What are the key safety considerations for high-pressure hydrogen storage?\", \n",
    "    \"answer\": \"N/A (Demo)\" \n",
    "}\n",
    "\n",
    "print(f\"üßê [Question ID {DEMO_TASK['id']}] Processing: {DEMO_TASK['question']}\")\n",
    "\n",
    "knowledge_group = KnowledgeGroup(LLM_CONFIG, MAX_ROUND)\n",
    "manager = knowledge_group.get_manager()\n",
    "\n",
    "user = autogen.UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    "    max_consecutive_auto_reply=1\n",
    ")\n",
    "\n",
    "task_payload = f\"\"\"Command: Query Task\n",
    "Context:\n",
    "- Query: \"{DEMO_TASK['question']}\"\n",
    "\n",
    "Instructions:\n",
    "Knowledge Augment(KG, RAG and Web) based on this query and then give the final answer.\"\"\"\n",
    "\n",
    "try:\n",
    "    chat_result = user.initiate_chat(\n",
    "        manager,\n",
    "        message=task_payload,\n",
    "        summary_method=\"reflection_with_llm\", \n",
    "        summary_args={\"summary_prompt\": \"Output the final report directly.\"}\n",
    "    )\n",
    "    final_answer = chat_result.summary\n",
    "    print(f\"\\n‚úÖ [Prediction]:\\n{final_answer}\\n\")\n",
    "\n",
    "    if not os.path.exists(WORK_DIR): os.makedirs(WORK_DIR)\n",
    "    output_file = os.path.join(WORK_DIR, \"demo_qa_result.jsonl\")\n",
    "    \n",
    "    result_item = {**DEMO_TASK, \"prediction\": final_answer}\n",
    "    \n",
    "    with open(output_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(result_item, ensure_ascii=False) + \"\\n\")s\n",
    "    print(f\"üìÇ Result saved to: {output_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a2a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Concept Cohort: P&ID Parsing\n",
    "import os, sys, autogen\n",
    "from configs import GPT_MINI_CONFIG, GEMINI_MINI_CONFIG \n",
    "try:\n",
    "    from CeProAgents import ConceptGroup\n",
    "    from CeProAgents.groups import clean_and_parse_json, save_json_file\n",
    "except ImportError:\n",
    "    sys.path.append(os.path.abspath(\"..\"))\n",
    "    from CeProAgents import ConceptGroup\n",
    "    from CeProAgents.groups import clean_and_parse_json, save_json_file\n",
    "\n",
    "INPUT_DIR = \"./CeProBench/concept/PID_image\"      \n",
    "OUTPUT_DIR = \"./results/concept/parse_demo\"       \n",
    "TARGET_ID = 1                                     \n",
    "LLM_CONFIG = GPT_MINI_CONFIG                       \n",
    "\n",
    "input_image_path = os.path.abspath(os.path.join(INPUT_DIR, f\"{TARGET_ID}.png\"))\n",
    "output_json_path = os.path.join(OUTPUT_DIR, f\"{TARGET_ID}_parse.json\")\n",
    "\n",
    "if os.path.exists(input_image_path):\n",
    "    print(f\"üñºÔ∏è [Processing Image]: {input_image_path}\")\n",
    "    \n",
    "    concept_group = ConceptGroup(LLM_CONFIG, current_mode=\"parsing_only\")\n",
    "    manager = concept_group.get_manager()\n",
    "    \n",
    "    user = autogen.UserProxyAgent(\n",
    "        name=\"User\",\n",
    "        human_input_mode=\"NEVER\",\n",
    "        code_execution_config=False,\n",
    "        max_consecutive_auto_reply=1\n",
    "    )\n",
    "\n",
    "    task_payload = f\"\"\"\n",
    "    **Task Type:** The Parsing Phase\n",
    "    **Instruction:** Parse the P&ID image at the following path: \"{input_image_path}\"\n",
    "    Call the parsing tool and return the JSON data.\n",
    "    \n",
    "    Example format (Reference only):\n",
    "    ```json\n",
    "    {{\n",
    "      \"equipments\": [{{\"identifier\": \"ÂÖ±Ê≤∏ÂâÇÂÜ∑ÂáùÂô®: E0301\", \"type\" : \"ÂÜ∑Âç¥/ÂÜ∑Âáù\"}}], \n",
    "      \"connections\": [{{\"source\": \"E0303\", \"target\" : \"E0401\"}}]\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        chat_result = user.initiate_chat(\n",
    "            manager,\n",
    "            message=task_payload,\n",
    "            summary_method=\"reflection_with_llm\",\n",
    "            summary_args={\n",
    "                \"summary_prompt\": \"Find the final JSON extracted from the image. Return ONLY the JSON code block.\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        content = chat_result.summary\n",
    "        if content:\n",
    "            pid_json = clean_and_parse_json(content) \n",
    "            if pid_json:\n",
    "                if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)\n",
    "                save_json_file(pid_json, output_json_path)\n",
    "                print(f\"‚úÖ [Success] Parsed data saved to: {output_json_path}\")\n",
    "                print(f\"üìä [Preview] Equipments found: {len(pid_json.get('equipments', []))}\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è [Warn] Failed to parse JSON content from response.\")\n",
    "        else:\n",
    "            print(\"‚ùå [Error] No response content received.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå [Exception]: {str(e)}\")\n",
    "else:\n",
    "    print(f\"‚ùå [Error] Image not found: {input_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Concept Cohort: Topology Completion \n",
    "import os, sys, autogen\n",
    "from configs import GPT_MINI_CONFIG\n",
    "\n",
    "try:\n",
    "    from CeProAgents import ConceptGroup\n",
    "    from CeProAgents.groups import clean_and_parse_json, save_json_file\n",
    "except ImportError:\n",
    "    sys.path.append(os.path.abspath(\"..\"))\n",
    "    from CeProAgents import ConceptGroup\n",
    "    from CeProAgents.groups import clean_and_parse_json, save_json_file\n",
    "\n",
    "INPUT_DIR = \"./CeProBench/concept/PID_complete\"  \n",
    "OUTPUT_DIR = \"./results/concept/completion_demo\" \n",
    "TARGET_ID = 1                                    \n",
    "LLM_CONFIG = GPT_MINI_CONFIG                    \n",
    "\n",
    "input_image_path = os.path.abspath(os.path.join(INPUT_DIR, f\"{TARGET_ID}_mask_new.png\"))\n",
    "output_json_path = os.path.join(OUTPUT_DIR, f\"{TARGET_ID}_completion.json\")\n",
    "\n",
    "if os.path.exists(input_image_path):\n",
    "    print(f\"üß© [Processing Masked Image]: {input_image_path}\")\n",
    "    \n",
    "    concept_group = ConceptGroup(LLM_CONFIG, current_mode=\"completion\")\n",
    "    manager = concept_group.get_manager()\n",
    "    \n",
    "    user = autogen.UserProxyAgent(\n",
    "        name=\"User\",\n",
    "        human_input_mode=\"NEVER\",\n",
    "        code_execution_config=False,\n",
    "        max_consecutive_auto_reply=1\n",
    "    )\n",
    "    task_payload = f\"\"\"\n",
    "    **Task Type:** The Completion Phase\n",
    "    \n",
    "    **Instruction:** \n",
    "    The P&ID image at the following path contains a **masked area** (white box or occlusion): \n",
    "    \"{input_image_path}\"\n",
    "    \n",
    "    Your goal is to infer the missing process logic and reconstruct the P&ID structure.\n",
    "    \n",
    "    **Steps:**\n",
    "    1. **Analyze Context:** Observe the pipelines and signals entering and exiting the masked area.\n",
    "    2. **Infer Logic:** Based on chemical engineering principles, deduce what equipments or connections are missing.\n",
    "    \n",
    "    **Output Requirement:**\n",
    "    - DO NOT replace the word 'mask' in the equipments list.\n",
    "    - Provide a \"completion\" field with a Top 10 ranking of likely equipment types.\n",
    "    \n",
    "    Example Schema:\n",
    "    ```json\n",
    "    {{\n",
    "        \"equipments\": [...],\n",
    "        \"connections\": [...],\n",
    "        \"completion\": [\n",
    "            \"Most Likely Type\", \"2nd Most Likely\", ..., \"10th Most Likely\"\n",
    "        ]\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        user.initiate_chat(manager, message=task_payload)\n",
    "        \n",
    "        real_content = None\n",
    "        for msg in reversed(concept_group.groupchat.messages):\n",
    "            content = msg.get(\"content\")\n",
    "            if msg.get(\"name\") == \"completer_expert\" and \"completion\" in str(content):\n",
    "                real_content = content\n",
    "                break\n",
    "        \n",
    "        if real_content:\n",
    "            pid_json = clean_and_parse_json(real_content)\n",
    "            if pid_json:\n",
    "                if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)\n",
    "                save_json_file(pid_json, output_json_path)\n",
    "                print(f\"‚úÖ [Success] Completion result saved to: {output_json_path}\")\n",
    "                print(f\"üèÜ [Top Prediction]: {pid_json.get('completion', [])[:3]} ...\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è [Warn] JSON parsing failed.\")\n",
    "        else:\n",
    "            print(\"‚ùå [Error] No valid completion output found in chat history.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå [Exception]: {str(e)}\")\n",
    "else:\n",
    "    print(f\"‚ùå [Error] Masked image not found: {input_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa45c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Concept Cohort: Generative Design\n",
    "import os, glob, json, autogen\n",
    "from configs import GPT_MINI_CONFIG\n",
    "\n",
    "try:\n",
    "    from CeProAgents import ConceptGroup\n",
    "    from CeProAgents.groups import clean_and_parse_json, save_json_file\n",
    "except ImportError:\n",
    "    import sys\n",
    "    sys.path.append(os.path.abspath(\"..\"))\n",
    "    from CeProAgents import ConceptGroup\n",
    "    from CeProAgents.groups import clean_and_parse_json, save_json_file\n",
    "\n",
    "INPUT_DIR = \"./CeProBench/concept/PID_generate\"    \n",
    "OUTPUT_DIR = \"./results/concept/generation_demo\"  \n",
    "LLM_CONFIG = GPT_MINI_CONFIG                      \n",
    "\n",
    "if not os.path.exists(INPUT_DIR): os.makedirs(INPUT_DIR)\n",
    "demo_prompt_path = os.path.join(INPUT_DIR, \"demo_case.txt\")\n",
    "if not os.path.exists(demo_prompt_path):\n",
    "    with open(demo_prompt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Design a simple P&ID for a water tank level control system. It should include a water tank, a feed pump, a level sensor, and a control valve.\")\n",
    "\n",
    "def process_single_prompt(concept_manager, user_proxy, file_path, output_dir):\n",
    "    file_basename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    print(f\"üìÑ [Processing Prompt]: {file_basename}\")\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        prompt_content = f.read().strip()\n",
    "\n",
    "    task_payload = f\"\"\"\n",
    "    **Task Type:** P&ID Generation\n",
    "    **Input Description:** \n",
    "    \"{prompt_content}\"\n",
    "\n",
    "    **Instruction:** \n",
    "    Based on the description above, design the P&ID and output the result in structured JSON format.\n",
    "    The JSON must adhere to the schema: {{ \"equipments\": [...], \"connections\": [...] }}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        user_proxy.initiate_chat(concept_manager, message=task_payload, summary_method=None)\n",
    "\n",
    "        history = concept_manager.groupchat.messages\n",
    "        first_draft = None\n",
    "        final_draft = None\n",
    "\n",
    "        for msg in history:\n",
    "            if msg.get(\"name\") == \"generator_expert\":\n",
    "                content = msg.get(\"content\", \"\")\n",
    "                parsed = clean_and_parse_json(content)\n",
    "                if parsed:\n",
    "                    if first_draft is None: first_draft = parsed\n",
    "                    final_draft = parsed \n",
    "        if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "        \n",
    "        if first_draft:\n",
    "            save_json_file(first_draft, os.path.join(output_dir, f\"{file_basename}_first.json\"))\n",
    "            print(f\"  üìù [First Draft] Saved.\")\n",
    "            \n",
    "        if final_draft:\n",
    "            save_json_file(final_draft, os.path.join(output_dir, f\"{file_basename}_final.json\"))\n",
    "            print(f\"  ‚úÖ [Final Result] Saved.\")\n",
    "            print(f\"  üìä [Stats] Equipments: {len(final_draft.get('equipments', []))}, Connections: {len(final_draft.get('connections', []))}\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå [Error] No valid JSON generated.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå [Exception]: {str(e)}\")\n",
    "\n",
    "concept_group = ConceptGroup(LLM_CONFIG, current_mode=\"generation\")\n",
    "concept_manager = concept_group.get_manager()\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_Proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    "    max_consecutive_auto_reply=1,\n",
    ")\n",
    "\n",
    "txt_files = glob.glob(os.path.join(INPUT_DIR, \"*.txt\"))\n",
    "print(f\"üìÇ Found {len(txt_files)} prompt files.\")\n",
    "\n",
    "for file_path in txt_files:\n",
    "    concept_manager.reset()\n",
    "    user_proxy.reset()\n",
    "    process_single_prompt(concept_manager, user_proxy, file_path, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b82dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Parameter Cohort: Simulation Optimization \n",
    "import os, json, logging, autogen\n",
    "from configs import CLAUDE_CONFIG, GPT_CONFIG\n",
    "try:\n",
    "    from CeProAgents import SimulationGroup\n",
    "    from CeProAgents.groups.parameter_group.aspen_utils import extract_aspen_block_set_parameters\n",
    "    from CeProAgents.groups.parameter_group.simulation_utils import extract_aspen_flowsheet_connections\n",
    "except ImportError:\n",
    "    import sys\n",
    "    sys.path.append(os.path.abspath(\"..\"))\n",
    "    from CeProAgents import SimulationGroup\n",
    "    from CeProAgents.groups.parameter_group.aspen_utils import extract_aspen_block_set_parameters\n",
    "    from CeProAgents.groups.parameter_group.simulation_utils import extract_aspen_flowsheet_connections\n",
    "\n",
    "INPUT_DIR = \"./CeProBench/parameter/cases\"        \n",
    "OUTPUT_DIR = \"./results/parameter/optimization\"    \n",
    "CASE_NAME = \"distillation_demo\"                   \n",
    "LLM_CONFIG = CLAUDE_CONFIG                         \n",
    "\n",
    "bkp_path = os.path.abspath(os.path.join(INPUT_DIR, f\"{CASE_NAME}.bkp\"))\n",
    "goal_path = os.path.abspath(os.path.join(INPUT_DIR, f\"{CASE_NAME}.txt\"))\n",
    "if os.path.exists(bkp_path) and os.path.exists(goal_path):\n",
    "    print(f\"üè≠ [Starting Optimization]: {CASE_NAME}\")\n",
    "    print(f\"üìÑ BKP File: {bkp_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(goal_path, 'r', encoding='utf-8') as f:\n",
    "            goal_content = f.read().strip()\n",
    "        print(\"‚è≥ Extracting Aspen Plus data (Connect via COM)...\")\n",
    "        pid_data = extract_aspen_flowsheet_connections(bkp_path)\n",
    "        param_data = extract_aspen_block_set_parameters(bkp_path)\n",
    "        print(\"‚úÖ Extraction complete.\")\n",
    "\n",
    "        global_context = {\n",
    "            \"bkp_file_path\": bkp_path,\n",
    "            \"pid_json\": pid_data,\n",
    "            \"optimization_goal\": goal_content\n",
    "        }\n",
    "        sim_group = SimulationGroup(llm_config=LLM_CONFIG, global_context=global_context)\n",
    "        manager = sim_group.get_manager()\n",
    "\n",
    "        user = autogen.UserProxyAgent(\n",
    "            name=\"User_Proxy\",\n",
    "            human_input_mode=\"NEVER\",\n",
    "            code_execution_config=False,\n",
    "            max_consecutive_auto_reply=1\n",
    "        )\n",
    "\n",
    "        task_payload = f\"\"\"\n",
    "        **Mission**: Optimize simulation parameters for project: {CASE_NAME}\n",
    "        **Context**:\n",
    "        - bkp_file_path: \"{bkp_path}\"\n",
    "        - optimization_goal: \"{goal_content}\"\n",
    "        - pid_json: {json.dumps(pid_data, ensure_ascii=False)}\n",
    "        - param_json: {json.dumps(param_data, ensure_ascii=False)}\n",
    "        \"\"\"\n",
    "\n",
    "        chat_result = user.initiate_chat(\n",
    "            manager,\n",
    "            message=task_payload,\n",
    "            summary_method=\"reflection_with_llm\",\n",
    "            summary_args={\"summary_prompt\": \"Extract the FINAL optimized parameters and metrics as a clean JSON object.\"}\n",
    "        )\n",
    "        if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)\n",
    "        \n",
    "        summary_file = os.path.join(OUTPUT_DIR, f\"{CASE_NAME}_summary.json\")\n",
    "        with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(chat_result.summary)\n",
    "            \n",
    "        history_file = os.path.join(OUTPUT_DIR, f\"{CASE_NAME}_history.json\")\n",
    "        with open(history_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(chat_result.chat_history, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "        print(f\"üéâ Optimization Finished! Results saved to: {OUTPUT_DIR}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå [Error]: {str(e)}\")\n",
    "        print(\"üí° Hint: Ensure Aspen Plus V11+ is installed and the license is active.\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è [Skip] Files not found. Please ensure {CASE_NAME}.bkp and .txt exist in {INPUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ce_agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
